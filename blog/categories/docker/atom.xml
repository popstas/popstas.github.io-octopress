<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Docker | Popstas]]></title>
  <link href="http://blog.popstas.ru/blog/categories/docker/atom.xml" rel="self"/>
  <link href="http://blog.popstas.ru/"/>
  <updated>2017-02-26T05:02:20+05:00</updated>
  <id>http://blog.popstas.ru/</id>
  <author>
    <name><![CDATA[Stanislav Popov]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Настройка кеширующего прокси Apt-cacher-ng для ускорения тестирования Ansible ролей с Molecule, Gitlab CI и Docker]]></title>
    <link href="http://blog.popstas.ru/blog/2017/02/26/apt-cacher-ng-for-testing-ansible-roles-with-docker-and-gitlab-ci/"/>
    <updated>2017-02-26T04:14:00+05:00</updated>
    <id>http://blog.popstas.ru/blog/2017/02/26/apt-cacher-ng-for-testing-ansible-roles-with-docker-and-gitlab-ci</id>
    <content type="html"><![CDATA[<p>В <a href="/blog/2017/02/24/why-you-should-not-use-apt-mirror-for-ansible-tests-in-docker/">предыдущей статье</a> я настраивал <code>apt-mirror</code> для тех же целей. У того способа нашлось несколько недостатков.</p>

<p>В статье ниже описано, как решить ту же проблему, используя <code>apt-cacher-ng</code>.</p>

<p>Tl;dr: на этот раз все получилось, этот способ меня устроил.</p>

<p><img src="http://blog.popstas.ru/images/2017-02/apt-cacher-ng.png" /></p>

<!-- more -->


<h2>Настройка apt-cacher-ng</h2>

<p>Здесь все довольно просто, проще, чем с <code>apt-mirror</code>.</p>

<pre><code>apt-get install apt-cacher-ng
</code></pre>

<p>В конфиге я задал пароль админа в <code>/etc/apt-cacher-ng/security.conf</code>, он дает право смотреть подробную статистику по cache-hit.</p>

<p>В <code>/etc/apt-cacher-ng/acng.conf</code> интересны следующие строчки:</p>

<ul>
<li><code>ExTreshold: 4</code> - устаревание кеша, в днях. Если файл ни разу не запрашивался дольше указанного времени, он будет удален. Я увеличил до 30 дней</li>
</ul>


<p>В остальном стандартный конфиг делает следующее:</p>

<ul>
<li>запускает веб-сервер для всего мира на <code>0.0.0.0:3142</code></li>
<li>хостит страничку и информацией о сервисе и статистикой на <a href="http://myserver.ru:3142">http://myserver.ru:3142</a></li>
<li>хранит кеши в <code>/var/cache/apt-cacher-ng</code></li>
</ul>


<p>После этого можно перезапустить сервис:
<code>
service apt-cacher-ng restart
</code></p>

<p>Проверяем, что он поднялся, должен открыться урл <code>http://myserver.ru:3142</code>.</p>

<h2>Настройка на клиентах</h2>

<p>На клиентах нужно добавить один файлик с указанием адреса прокси, <code>sources.list</code> менять не надо:
<code>
echo 'Acquire::http::Proxy "http://myserver.ru:3142";' &gt; /etc/apt/apt.conf.d/00aptproxy
</code></p>

<p>На хосте я этого делать не стал, т.к. у меня там стоит старая Ubuntu 14.04, а тестирую я на Ubuntu 16.04. К слову, apt-cacher-ng это не волнует, он нормально кеширует новые пакеты, не смотря на то, что стоит на старой оси. Как я понимаю, его можно использовать и в смешанном режиме, то есть кешировать пакеты сразу от нескольких версий операционок, но я это не проверял.</p>

<p>Вместо этого я положил файлик с указанием прокси в отдельную папку, откуда я буду пробрасывать его внутрь тестовых контейнеров:
<code>
echo 'Acquire::http::Proxy "http://myserver.ru:3142";' &gt; /usr/local/src/00aptproxy
</code></p>

<h2>Использование с Molecule, Gitlab CI и Travis CI</h2>

<p>Не знаю зачем, но роли я тестирую сразу двумя CI: Gitlab и Travis. В связи с этим появляется проблема: нужно на Gitlab CI использовать один кеширующий сервер, при локальном тестировании другой, а для Travis CI убирать его.</p>

<p>Сложность в том, что Molecule не поддерживает разные конфиги, только умеет использовать в конфигах переменные окружения. Это я и использовал.</p>

<p>Смысл в том, что на разных CI в контейнер будут пробрасываться разные <code>/etc/apt/apt.conf.d/00aptproxy</code>, для Travis это будет просто пустой файл.</p>

<p><code>.travis.yml</code>:
<code>
script:
  - export MOLECULE_APTPROXY_PATH="$PWD/00aptproxy"
  - touch "$MOLECULE_APTPROXY_PATH"
  - molecule --debug test
</code></p>

<p><code>molecule.yml</code>:
<code>
docker:
  containers:
    - name: ansible-role-mysql
      image: ubuntu
      image_version: latest
      volume_mounts:
        - ${MOLECULE_APTPROXY_PATH}:/etc/apt/apt.conf.d/00aptproxy
</code></p>

<p><code>.gitlab-ci.yml</code> я решил не менять, вместо этого я изменил способ регистрации раннеров в Gitlab CI, используются специальные раннеры с проброшенной переменной окружения:</p>

<pre><code>gitlab-ci-multi-runner register -n \
  --executor docker \
  --description "Docker at myserver.ru on popstas/ubuntu-molecule" \
  --docker-image "popstas/ubuntu-molecule:latest" \
  --docker-volumes /var/run/docker.sock:/var/run/docker.sock \
  --env "MOLECULE_APTPROXY_PATH=/usr/local/src/00aptproxy"
</code></pre>

<p>Это сделано потому, что я еще запускаю локальные раннеры, хотелось сделать так, чтобы <code>.gitlab-ci.yml</code> подходил во всех случаях.</p>

<p>На локальной машине можно просто добавить переменные окружения через <code>export</code> прямо в терминале или добавить их в ваш <code>~/.profile</code>, тогда можно просто запускать <code>molecule test</code> и все будет работать.</p>

<h2>Тестирование скорости</h2>

<p>Дополню таблицу из <a href="/blog/2017/02/24/why-you-should-not-use-apt-mirror-for-ansible-tests-in-docker/">прошлой статьи</a>. Естественно, указано время второго прогона apt-cacher-ng для роли, т.к. в первый запуск пакеты еще не скачались, и скорость будет как при использовании стандартного репозитория.</p>

<table>
<thead>
<tr>
<th>Роль                </th>
<th> archive.ubuntu.org </th>
<th> apt-mirror </th>
<th> apt-cacher-ng </th>
<th> Travis CI:</th>
</tr>
</thead>
<tbody>
<tr>
<td>ansible-role-common </td>
<td> 8:04               </td>
<td> 6:18       </td>
<td> 6:30          </td>
<td> <strong>4:32</strong></td>
</tr>
<tr>
<td>ansible-role-mysql  </td>
<td> 3:41               </td>
<td> <strong>3:22</strong>   </td>
<td> 3:26          </td>
<td> 3:46</td>
</tr>
<tr>
<td>ansible-role-zsh    </td>
<td> 3:16               </td>
<td> <strong>2:54</strong>   </td>
<td> 2:56          </td>
<td> 4:08</td>
</tr>
</tbody>
</table>


<p>Как видим, в скорости решение с <code>apt-cacher-ng</code> по сравнению с <code>apt-mirror</code> почти не теряет. Если не видно разницы, зачем тратить лишние 140 Гб?</p>

<p>Кстати, скорость тестирования увеличилась и на других способах, которые я описывал в прошлой статье: если тогда разница между способами была 20-30%, то теперь она сократилась до 10-20%. Это говорит о том, что если ничего не делать и пользоваться стандартными удаленными репозиториями, вы будете больше зависеть от внешних факторов.</p>

<h2>Выводы</h2>

<h3>Минусы:</h3>

<ul>
<li>Подходит только для множественного запуска однотипных установок, в моем случае так и есть</li>
<li>Немного медленнее, чем при использовании зеркала, минусом это назвать сложно, т.к. разница всего 1-3%</li>
<li>Нужно пробрасывать порт через фаервол, если хотите открыть прокси всему миру, я этого делать не стал :)</li>
</ul>


<h3>Плюсы:</h3>

<ul>
<li>Хранит только нужные пакеты</li>
<li>Кеширует не только пакеты из стандартного репозитория, но и внешние пакеты, которые вы добавляете в <code>sources.list</code></li>
<li>Не требует изменения sources.list</li>
<li>Проше настраивать</li>
<li>Не нужен веб-сервер (nginx)</li>
<li>По умолчанию фаервол закрывает вас</li>
</ul>


<p>Как видите, минусы надуманны, а плюсы реальны. На этом история ускорения скачивания пакетов закончена, но остается еще много интересных моментов в тестировании Ansible на Gitlab CI, продолжение следует.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Как я создал и отказался от локального репозитория Apt-mirror для Ubuntu для ускорения тестирования Ansible ролей]]></title>
    <link href="http://blog.popstas.ru/blog/2017/02/24/why-you-should-not-use-apt-mirror-for-ansible-tests-in-docker/"/>
    <updated>2017-02-24T17:39:00+05:00</updated>
    <id>http://blog.popstas.ru/blog/2017/02/24/why-you-should-not-use-apt-mirror-for-ansible-tests-in-docker</id>
    <content type="html"><![CDATA[<p>При тестировании плейбуков на чистой Ubuntu (а как же еще?) самые большие накладные расходы по времени (субъективно)
и уж точно самые большие по трафику уходят на установку пакетов из системного репозитория. Особенно это заметно, когда видишь, что один и тот же тест Travis CI прогоняет в 1.5 раза быстрее.</p>

<p>Ниже описано, как создать зеркало из <a href="http://mirror.yandex.ru/ubuntu">http://mirror.yandex.ru/ubuntu</a> и подружить его с Gitlab CI и molecule.</p>

<p>Tl;dr: не делайте локальный репозиторий через <code>apt-mirror</code> для мелких задач, не стоит оно того. Вместо этого нужно поднять кеширующий сервер через <a href="/blog/2017/02/26/apt-cacher-ng-for-testing-ansible-roles-with-docker-and-gitlab-ci/">apt-cacher-ng</a>.</p>

<p><img src="http://blog.popstas.ru/images/2017-02/apt-mirror.png" /></p>

<!-- more -->


<h2>Настройка apt-mirror</h2>

<p>Для синхронизации локального репозитория с основным вариант один - <code>apt-mirror</code>.
<a href="https://apt-mirror.github.io">Официальный сайт</a> считает нас умными, поэтому все его инструкции заключаются в 3 строчках:
<code>bash
apt-get install apt-mirror
nano /etc/apt/mirror.list
sudo apt-mirror
</code></p>

<p>Все действительно почти так просто. Почти.</p>

<h3>Выбор самого быстрого репозитория</h3>

<p>Пока гуглил тему, случайно наткнулся на <a href="https://hub.docker.com/r/evgeniyklemin/ubuntu-fastest-apt-mirror/">инструкцию</a>, как выбрать самый быстрый репозиторий.
Скорее всего, для нас для всех это будет <a href="http://mirror.yandex.ru/ubuntu,">http://mirror.yandex.ru/ubuntu,</a> но можно в этом убедиться:</p>

<pre><code class="bash">wget -q -nv -O- http://ftp.ru.debian.org/debian/pool/main/n/netselect/netselect_0.3.ds1-26_amd64.deb &gt; /tmp/netselect_0.3.ds1-26_amd64.deb
dpkg -i /tmp/netselect_0.3.ds1-26_amd64.deb
netselect -s3 -t20 `wget -q -nv -O- https://launchpad.net/ubuntu/+archivemirrors | grep -P -B8 "statusUP|statusSIX" | grep -o -P "(f|ht)tp.*\"" | tr '"\n' '  '`
</code></pre>

<p>Пакета нет в репозитории Ubuntu, поэтому качаем из репозитория Debian
В результате вы получите список из 3 самых быстрых (по пингу) репозиториев:</p>

<pre><code>54 http://mirror.yandex.ru/ubuntu/
89 http://ubuntu.volia.net/ubuntu-archive/
124 http://nl.archive.ubuntu.com/ubuntu/
</code></pre>

<h3>Конфигурация</h3>

<p>Открываем <code>/etc/apt/mirror.list</code>.</p>

<ul>
<li>Меняем <code>archive.ubuntu.com</code> на <code>mirror.yandex.ru</code>.</li>
<li>Убираем <code>multiverse</code> репозиторий (в стандартном Docker контейнере <code>ubuntu</code> его нет, видимо не очень нужен, зато экономим сразу 13 Гб).</li>
<li>Меняем путь хранения зеркала, не забывая после этого скопировать пустой скрипт в новое место <code>/var/spool/apt-mirror/var/postmirror.sh</code>, иначе <code>apt-mirror</code> будет в конце падать с ошибкой. У меня зеркало будет храниться в <code>/var/backups/apt-mirror</code> (на диске с бекапами места много)</li>
</ul>


<p>Это же в виде команд:
<code>bash
sed -i /etc/apt/mirror.list 's/archive.ubuntu.com/mirror.yandex.ru/g'
sed -i /etc/apt/mirror.list 's/ multiverse//g'
sed -i /etc/apt/mirror.list 's/\/var\/spool\/apt-mirror/\var\/backups\/apt-mirror/g'
mkdir -p /var/backups/apt-mirror/var
cp /var/spool/apt-mirror/var/postmirror.sh /var/backups/apt-mirror/var
</code></p>

<p>Добавляем в cron задание по обновлению репозитория, я буду запускать в 1 ночи:
<code>bash
sed -i 's/#0 4/0 1/g' /etc/cron.d/apt-mirror
</code></p>

<p>Настраиваем nginx на отдачу репозитория, у меня конфиг такой:
<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>server <span class="o">{</span>
</span><span class='line'>  listen 80<span class="p">;</span>
</span><span class='line'>  server_name mirror.myserver.ru<span class="p">;</span>
</span><span class='line'>  root /var/backups/apt-mirror/mirror/mirror.yandex.ru<span class="p">;</span>
</span><span class='line'>  access_log off<span class="p">;</span>&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  location / <span class="o">{</span>
</span><span class='line'>    autoindex on<span class="p">;</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></p>

<p>Все готово, осталось запустить <code>apt-mirror</code> и подождать денек: у меня выкачивалось 142 Гб.
Причем обновления тоже будут весить ощутимо, как я понял: через день я запустил apt-mirror еще раз,
он скачал 1.5 Гб.</p>

<p>Проверяем URL <a href="http://mirror.myserver.ru/,">http://mirror.myserver.ru/,</a> там должен быть доступен каталог <code>ubuntu</code>.</p>

<p>После этого можете сменить системные репозитории в ваших локальных убунтах и наслаждаться скоростью.</p>

<h3>Ошибка при apt-get update: binary-i386/Packages: 404  Not Found</h3>

<p>Хотя нет, насладиться сразу конечно не получилось. По какой-то причине (наверное причина в месте на диске), apt-mirror выкачивает только amd64 пакеты, из-за чего <code>apt-get update</code> ругается:
<code>
W: The repository 'http://apt.myserver.ru/ubuntu xenial-backports Release' does not have a Release file.
W: Failed to fetch http://apt.myserver.ru/ubuntu/dists/xenial/main/binary-i386/Packages: 404  Not Found
W: Failed to fetch http://apt.myserver.ru/ubuntu/dists/xenial-updates/main/binary-i386/Packages: 404  Not Found
E: Some index files failed to download. They have been ignored, or old ones used instead.
</code></p>

<p>Казалось бы ничего страшного, но уверен, что в тестах ненулевой код выхода apt-get будет все останавливать, поэтому придется чинить.</p>

<p>Ошибка есть на <a href="https://askubuntu.com/questions/465303/apt-mirror-error/574141">askubuntu.com</a>, спасибо человеку, который предложил решение и негодовал по поводу того, что есть только в <code>man sources.list</code>.</p>

<p>Решение напрашивается: явно указывать в <code>sources.list</code>, что в репозитории только amd64 пакеты, то есть вместо:
<code>
deb [ arch=amd64 ] http://apt.myserver.ru/ubuntu/ xenial main restricted universe
</code></p>

<p>С настройкой <code>apt-mirror</code> закончили, перейдем к использованию в тестах.</p>

<hr />

<h2>Переключение Docker контейнера на локальный apt репозиторий</h2>

<p><a href="https://github.com/ekino/docker-images/tree/master/apt-mirror">https://github.com/ekino/docker-images/tree/master/apt-mirror</a> - здесь приведено 2 способа настройки репозитория в контейнере, не изменяя его:</p>

<ol>
<li>[Плохой способ] Подмена через DNS</li>
<li>[Хороший способ] Подмена <code>/etc/apt/sources.list</code></li>
</ol>


<p>Я выбрал хороший. Делается это монтированием файла на место <code>/etc/apt/sources.list</code>:</p>

<pre><code class="bash">FQDN="apt.myserver.ru"
cat &lt;&lt;EOF &gt; sources.list-$FQDN
deb [ arch=amd64 ] http://$FQDN/ubuntu/ xenial main restricted universe
deb [ arch=amd64 ] http://$FQDN/ubuntu/ xenial-updates main restricted universe
deb [ arch=amd64 ] http://$FQDN/ubuntu/ xenial-security main restricted universe
EOF
</code></pre>

<p>Чтобы не тащить с собой артефакты, файл создается командой.</p>

<p>После этого проверяем, это должно отработать нормально:
<code>bash
docker run --rm -it -v $(readlink -f sources.list-$FQDN):/etc/apt/sources.list ubuntu:16.04 apt-get update
</code></p>

<p>Если <code>readlink</code> выдает ошибку <code>readlink: illegal option -- f</code>, тогда вы скорее всего сидите на MacOS и вам нужно сделать <code>brew install coreutils</code> и прописать в переменную <code>PATH</code> то, что он просит.</p>

<h2>Сравнение скорости</h2>

<p>Я потратил около 4 часов на то, чтобы настроить локальные репозитории, посмотрим, сколько я сэкономил времени.
Скорость инета у меня 30 мбит.</p>

<p>Я сравнил отработку <code>time molecule test</code> на 3 ansible ролях, вот результаты:</p>

<table>
<thead>
<tr>
<th>Роль                </th>
<th> Стандартный репозиторий </th>
<th> Локальный репозиторий </th>
<th> Travis CI:</th>
</tr>
</thead>
<tbody>
<tr>
<td>ansible-role-common </td>
<td> 8:04                    </td>
<td> 6:18                  </td>
<td> <strong>4:32</strong></td>
</tr>
<tr>
<td>ansible-role-mysql  </td>
<td> 3:41                    </td>
<td> <strong>3:22</strong>              </td>
<td> 3:46</td>
</tr>
<tr>
<td>ansible-role-zsh    </td>
<td> 3:29                    </td>
<td> <strong>2:54</strong>              </td>
<td> 4:08</td>
</tr>
</tbody>
</table>


<hr />

<p>Как видно, прирост небольшой, всего 20-30%.
UPD 26.02.2017: на при написании <a href="/blog/2017/02/26/apt-cacher-ng-for-testing-ansible-roles-with-docker-and-gitlab-ci/">статьи про apt-cacher-ng</a> я перепроверил результаты и разница сократилась до 10-20%.</p>

<p>Тут надо заметить, что в <code>test</code> входит проверка идемпотентности, где никакие пакеты не ставятся. Тогда я сравнил время выполнения &lsquo;molecule converge&rsquo; для <code>ansible-role-mysql</code> и получил немного лучшие результаты: 2:30 против 3:17, это уже почти в 2 раза быстрее.</p>

<table>
<thead>
<tr>
<th>Роль                </th>
<th> Стандартный репозиторий </th>
<th> Локальный репозиторий</th>
</tr>
</thead>
<tbody>
<tr>
<td>ansible-role-common </td>
<td> 8:15                    </td>
<td> 6:09</td>
</tr>
<tr>
<td>ansible-role-mysql  </td>
<td> 3:17                    </td>
<td> 2:30</td>
</tr>
<tr>
<td>ansible-role-zsh    </td>
<td> 4:05                    </td>
<td> 2:43</td>
</tr>
</tbody>
</table>


<h2>Выводы по поводу apt-mirror</h2>

<p>Результаты меня немного расстроили. Оказалось, что поразительного прироста в скорости, на который я надеялся, не будет.</p>

<h3>Плюсы:</h3>

<ul>
<li>один раз потратил время, чтобы при каждом тесте ждать меньше</li>
<li>уменьшает желание тестировать не на чистой машине</li>
<li>интернет-канал не занимается в рабочее время</li>
</ul>


<h3>Минусы</h3>

<ul>
<li>эффект слабый, 20-30%</li>
<li>сложности с пробросом файла <code>sources.list</code></li>
<li>уход от стандартной конфигурации Gitlab CI</li>
<li>разные конфиги для Travis CI и Gitlab CI</li>
</ul>


<p>На основе этого сделал для себя вывод: это подходит только для локального постоянного применения, в остальных случаях минусы перевешивают.</p>

<h2>Что-то тут не так&hellip;</h2>

<p>После этого я задумался: а как делают &ldquo;большие&rdquo;? Из серьезных решений для локальных репозиториев я знаю только Artifactory. Пошел посмотреть, как у них обстоят дела с зеркалами и <a href="https://www.jfrog.com/knowledge-base/how-to-mirror-a-remote-repository/">нашел</a>: они умеют быть зеркалом, но не рекоменуют их так использовать, т.к. это неэффективно. Вместо этого они предлагают пользоваться ими как кеширующим сервером. Такие дела&hellip;</p>

<p>UPD 26.02.2017: перешел на использование apt-cacher-ng, в моем случае он лучше по всем параметрам, подробности читайте в продолжении</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker в картинках]]></title>
    <link href="http://blog.popstas.ru/blog/2016/02/26/docker-in-images/"/>
    <updated>2016-02-26T21:29:45+05:00</updated>
    <id>http://blog.popstas.ru/blog/2016/02/26/docker-in-images</id>
    <content type="html"><![CDATA[<p>Оставлю здесь <a href="http://habrahabr.ru/post/272145/">свой пост</a> с хабра.</p>

<p><em>Перевод поста <a href="http://merrigrove.blogspot.co.uk/2015/10/visualizing-docker-containers-and-images.html">Visualizing Docker Containers and Images</a>, от новичка к новичкам, автор на простых примерах объясняет базовые сущности и процессы в использовании docker.</em></p>

<p>Если вы не знаете, что такое Docker или не понимаете, как он соотносится с виртуальными машинами или с инструментами configuration management, то этот пост может показаться немного сложным.</p>

<p>Пост предназначен для тех, кто пытается освоить docker cli, понять, чем отличается контейнер и образ. В частности, будет объяснена разница между просто контейнером и запущенным контейнером.
<img class="<a" src="href="https://habrastorage.org/files/8ff/349/fb2/8ff349fb23f840589c479d029964b8dc.png">https://habrastorage.org/files/8ff/349/fb2/8ff349fb23f840589c479d029964b8dc.png</a>"></p>

<!-- more -->


<p>В процессе освоения нужно представить себе некоторые лежащие в основе детали, например, слои файловой системы UnionFS. В течение последней пары недель я изучал технологию, я новичок в мире docker, и командная строка docker показалась мне довольно сложной для освоения.</p>

<p>По-моему, понимание того, как технология работает изнутри - лучший способ быстро освоить новый инструмент и правильно его использовать. Часто новая технология разрабатывает новые модели абстракций и привносит новые термины и метафоры, которые могут быть как будто бы понятны в начале, но без четкого понимания затрудняют последующее использование инструмента.</p>

<p>Хорошим примером является Git. Я не мог понять Git, пока не понял его базовую модель, включая trees, blobs, commits, tags, tree-ish и прочее. Я думаю, что люди, не понимающие внутренности Git, не могут мастерски использовать этот инструмент.</p>

<h2>Определение образа (Image)</h2>

<p>Визуализация образа представлена ниже в двух видах. Образ можно определить как &ldquo;сущность&rdquo; или &ldquo;общий вид&rdquo; (union view) стека слоев только для чтения.</p>

<p><img class="<a" src="href="https://habrastorage.org/files/243/a01/1ed/243a011ed04f455099a4ba64a87736f6.png">https://habrastorage.org/files/243/a01/1ed/243a011ed04f455099a4ba64a87736f6.png</a>"></p>

<p>Слева мы видим стек слоев для чтения. Они показаны только для понимания внутреннего устройства, они доступны вне запущенного контейнера на хост-системе. Важно то, что они доступны только для чтения (иммутабельны), а все изменения происходят в верхнем слое стека. Каждый слой может иметь одного родителя, родитель тоже имеет родителя и т.д. Слой верхнего уровня может быть использован как UnionFS (AUFS в моем случае с docker) и представлен в виде единой read-only файловой системы, в которой отражены все слои. Мы видим эту &ldquo;сущность&rdquo; образа на рисунке справа.</p>

<p>Если вы захотите посмотреть на эти слои в первозданном виде, вы можете найти их в файловой системе на хост-машине. Они не видны напрямую из запущенного контейнера. На моей хост-машине я могу найти образы в /var/lib/docker/aufs.</p>

<pre><code># sudo tree -L 1 /var/lib/docker/
/var/lib/docker/
├── aufs
├── containers
├── graph
├── init
├── linkgraph.db
├── repositories-aufs
├── tmp
├── trust
└── volumes

7 directories, 2 files
</code></pre>

<h2>Определение контейнера (Container)</h2>

<p>Контейнер можно назвать &ldquo;сущностью&rdquo; стека слоев с верхним слоем для записи.</p>

<p><img class="<a" src="href="https://habrastorage.org/files/8d3/d29/494/8d3d29494dbf46f79b1be15cea7516c4.png">https://habrastorage.org/files/8d3/d29/494/8d3d29494dbf46f79b1be15cea7516c4.png</a>"></p>

<p>На изображении выше показано примерно то же самое, что на изображении про образ, кроме того, что верхний слой доступен для записи. Вы могли заметить, что это определение ничего не говорит о том, запущен контейнер или нет и это неспроста. Разделение контейнеров на запущенные и не запущенные устранило путаницу в моем понимании.</p>

<p>Контейнер определяет лишь слой для записи наверху образа (стека слоев для чтения). Он не запущен.</p>

<h2>Определение запущенного контейнера</h2>

<p>Запущенный контейнер - это &ldquo;общий вид&rdquo; контейнера для чтения-записи и его изолированного пространства процессов. Ниже изображен контейнер в своем пространстве процессов.</p>

<p><img class="<a" src="href="https://habrastorage.org/files/c72/5d3/b0b/c725d3b0be5742aca5f50310d640d0b1.png">https://habrastorage.org/files/c72/5d3/b0b/c725d3b0be5742aca5f50310d640d0b1.png</a>"></p>

<p>Изоляция файловой системы обеспечивается технологиями уровня ядра, cgroups, namespaces и другие, позволяют докеру быть такой перспективной технологией. Процессы в пространстве контейнера могут изменять, удалять или создавать файлы, которые сохраняются в верхнем слое для записи. Смотрите изображение:</p>

<p><img class="<a" src="href="https://habrastorage.org/files/f8e/bbf/e3b/f8ebbfe3b59346ee9cdb017b89fcb169.png">https://habrastorage.org/files/f8e/bbf/e3b/f8ebbfe3b59346ee9cdb017b89fcb169.png</a>"></p>

<p>Чтобы проверить это, выполните команду на хост-машине:</p>

<p><source lang="bash">
docker run ubuntu touch happiness.txt
</source>
Вы можете найти новый файл в слое для записи на хост-машине, даже если контейнер не запущен.</p>

<p><source lang="bash"></p>

<h1>find / -name happiness.txt</h1>

<p>/var/lib/docker/aufs/diff/860a7b&hellip;889/happiness.txt
</source></p>

<h2>Определение слоя образа (Image layer)</h2>

<p>Наконец, мы определим слой образа. Изображение ниже представляет слой образа и дает нам понять, что слой - это не просто изменения в файловой системе.</p>

<p><img class="<a" src="href="https://habrastorage.org/files/928/23a/1a0/92823a1a03ad487586293f37e78cf74f.png">https://habrastorage.org/files/928/23a/1a0/92823a1a03ad487586293f37e78cf74f.png</a>"></p>

<p>Метаданные - дополнительная информация о слое, которая позволяет докеру сохранять информацию во время выполнения и во время сборки. Оба вида слоев (для чтения и для записи) содержат метаданные.</p>

<p><img class="<a" src="href="https://habrastorage.org/files/b7e/d04/252/b7ed042525f647b986009b82d18b3fee.png">https://habrastorage.org/files/b7e/d04/252/b7ed042525f647b986009b82d18b3fee.png</a>"></p>

<p>Кроме того, как мы уже упоминали раньше, каждый слой содержит указатель на родителя, используя id (на изображении родительские слои внизу). Если слой не указывает на родительский слой, значит он наверху стека.</p>

<p><img class="<a" src="href="https://habrastorage.org/files/7e9/de2/c4f/7e9de2c4f537438c8f5357d09c398289.png">https://habrastorage.org/files/7e9/de2/c4f/7e9de2c4f537438c8f5357d09c398289.png</a>"></p>

<h5>Расположение метаданных</h5>


<p>На данный момент (я понимаю, что разработчики docker могут позже сменить реализацию), метаданные слоев образов (для чтения) находятся в файле с именем &ldquo;json&rdquo; в папке /var/lib/docker/graph/id_слоя:</p>

<pre><code>/var/lib/docker/graph/e809f156dc985.../json
</code></pre>

<p>где &ldquo;e809f156dc985&hellip;&rdquo; - урезанный id слоя.</p>

<h2>Свяжем все вместе</h2>

<p>Теперь, давайте посмотрим на команды, иллюстрированные понятными картинками.</p>

<h3>docker create <image-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png">https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png">https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png</a>"></p>

<p>Команда &lsquo;docker create&rsquo; добавляет слой для записи наверх стека слоев, найденного по <image-id>. Команда не запускает контейнер.</p>

<p><img class="<a" src="href="https://habrastorage.org/files/12c/8d5/606/12c8d56068c5416e8ca003b532ef3cdb.png">https://habrastorage.org/files/12c/8d5/606/12c8d56068c5416e8ca003b532ef3cdb.png</a>"></p>

<h3>docker start <container-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png">https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/730/6c4/4cd/7306c44cdfdd4ead9f1f073d91dd312c.png">https://habrastorage.org/files/730/6c4/4cd/7306c44cdfdd4ead9f1f073d91dd312c.png</a>"></p>

<p>Команда &lsquo;docker start&rsquo; создает пространство процессов вокруг слоев контейнера. Может быть только одно пространство процессов на один контейнер.</p>

<h3>docker run <image-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png">https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/730/6c4/4cd/7306c44cdfdd4ead9f1f073d91dd312c.png">https://habrastorage.org/files/730/6c4/4cd/7306c44cdfdd4ead9f1f073d91dd312c.png</a>"></p>

<p>Один из первых вопросов, который задают люди (я тоже задавал): &ldquo;В чем разница между &lsquo;docker start&rsquo; и &lsquo;docker run&rsquo;?&rdquo; Одна из первоначальных целей этого поста - объяснить эту тонкость.</p>

<p><img class="<a" src="href="https://habrastorage.org/files/429/f39/fc6/429f39fc67d44579a40365018dc6839e.png">https://habrastorage.org/files/429/f39/fc6/429f39fc67d44579a40365018dc6839e.png</a>"></p>

<p>Как мы видим, команда &lsquo;docker run&rsquo; находит образ, создает контейнер поверх него и запускает контейнер. Это сделано для удобства и скрывает детали двух команд.</p>

<p>Продолжая сравнение с освоением Git, я скажу, что &lsquo;docker run&rsquo; очень похожа на &lsquo;git pull&rsquo;. Так же, как и &lsquo;git pull&rsquo; (который объединяет &lsquo;git fetch&rsquo; и &lsquo;git merge&rsquo;), команда &lsquo;docker run&rsquo; объединяет две команды, которые могут использоваться и независимо. Это удобно, но поначалу может ввести в заблуждение.</p>

<h3>docker ps</h3>

<p><img class="<a" src="href="https://habrastorage.org/files/441/0ed/8b7/4410ed8b7bb94de68dfae60a79a08aca.png">https://habrastorage.org/files/441/0ed/8b7/4410ed8b7bb94de68dfae60a79a08aca.png</a>"></p>

<p>Команда &lsquo;docker ps&rsquo; выводит список запущенных контейнеров на вашей хост-машине. Важно понимать, что в этот список входят только запущенные контейнеры, не запущенные контейнеры скрыты. Чтобы посмотреть список всех контейнеров, нужно использовать следующую команду.</p>

<h3>docker ps -a</h3>

<p><img class="<a" src="href="https://habrastorage.org/files/633/55a/c1a/63355ac1a27d4cf6a1f10142cc89d7b0.png">https://habrastorage.org/files/633/55a/c1a/63355ac1a27d4cf6a1f10142cc89d7b0.png</a>"></p>

<p>Команда &lsquo;docker ps -a&rsquo;, где &lsquo;a&rsquo; - сокращение от &lsquo;all&rsquo; выводит список всех контейнеров, независимо от их состояния.</p>

<h3>docker images</h3>

<p><img class="<a" src="href="https://habrastorage.org/files/2d2/29e/bc6/2d229ebc667244b3b478298aa3162c7e.png">https://habrastorage.org/files/2d2/29e/bc6/2d229ebc667244b3b478298aa3162c7e.png</a>"></p>

<p>Команда &lsquo;docker images&rsquo; выводит список образов верхнего уровня (top-level images). Фактически, ничего особенного не отличает образ от слоя для чтения. Только те образы, которые имеют присоединенные контейнеры или те, что были получены с помощью pull, считаются образами верхнего уровня. Это различие нужно для удобства, так как за каждым образом верхнего уровня может быть множество слоев.</p>

<h3>docker images -a</h3>

<p><img class="<a" src="href="https://habrastorage.org/files/5b6/6a9/fd9/5b66a9fd93ce4157b3cfa48984a5ca0d.png">https://habrastorage.org/files/5b6/6a9/fd9/5b66a9fd93ce4157b3cfa48984a5ca0d.png</a>"></p>

<p>Команда &lsquo;docker images -a&rsquo; выводит все образы на хост-машине. Это фактически список всех слоев для чтения в системе. Если вы хотите увидеть все слои одного образа, воспользуйтесь командой &lsquo;docker history&rsquo;.</p>

<h3>docker stop <container-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/f34/430/e32/f34430e3231842e3b748d337993e9338.png">https://habrastorage.org/files/f34/430/e32/f34430e3231842e3b748d337993e9338.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png">https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png</a>"></p>

<p>Команда &lsquo;docker stop&rsquo; посылает сигнал SIGTERM запущенному контейнеру, что мягко останавливает все процессы в пространстве процессов контейнера. В результате мы получаем не запущенный контейнер.</p>

<h3>docker kill <container-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/ef8/c77/3c3/ef8c773c34454292b76f798482e15463.png">https://habrastorage.org/files/ef8/c77/3c3/ef8c773c34454292b76f798482e15463.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png">https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png</a>"></p>

<p>Команда &lsquo;docker kill&rsquo; посылает сигнал SIGKILL, что немедленно завершает все процессы в текущем контейнере. Это почти то же самое, что нажать Ctrl+\ в терминале.</p>

<h3>docker pause <container-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/63d/de7/ed4/63dde7ed482544e0afcc2925eabc1e3d.png">https://habrastorage.org/files/63d/de7/ed4/63dde7ed482544e0afcc2925eabc1e3d.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/70d/208/439/70d208439a1944739c5e06e716ab1975.png">https://habrastorage.org/files/70d/208/439/70d208439a1944739c5e06e716ab1975.png</a>"></p>

<p>В отличие от &lsquo;docker stop&rsquo; и &lsquo;docker kill&rsquo;, которые посылают настоящие UNIX сигналы процессам контейнера, команда &lsquo;docker pause&rsquo; используют специальную возможность cgroups для заморозки запущенного пространства процессов. Подробности можно прочитать <a href="https://www.kernel.org/doc/Documentation/cgroups/freezer-subsystem.txt">здесь</a>, если вкратце, отправки сигнала Ctrl+Z (SIGTSTP) не достаточно, чтобы заморозить все процессы в пространстве контейнера.</p>

<h3>docker rm <container-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/92d/14d/d92/92d14dd9224043079a90ab80c4dbc6a6.png">https://habrastorage.org/files/92d/14d/d92/92d14dd9224043079a90ab80c4dbc6a6.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/a36/292/8c4/a362928c4661422797d267560ff38182.png">https://habrastorage.org/files/a36/292/8c4/a362928c4661422797d267560ff38182.png</a>"></p>

<p>Команда &lsquo;docker rm&rsquo; удаляет слой для записи, который определяет контейнер на хост-системе. Должна быть запущена на остановленном контейнерах. Удаляет файлы.</p>

<h3>docker rmi <image-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/4c2/eb5/26a/4c2eb526a35e4751a5302c954370a0fa.png">https://habrastorage.org/files/4c2/eb5/26a/4c2eb526a35e4751a5302c954370a0fa.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/3a2/145/38a/3a214538a6e54e009f704825109393a1.png">https://habrastorage.org/files/3a2/145/38a/3a214538a6e54e009f704825109393a1.png</a>"></p>

<p>Команда &lsquo;docker rmi&rsquo; удаляет слой для чтения, который определяет &ldquo;сущность&rdquo; образа. Она удаляет образ с хост-системы, но образ все еще может быть получен из репозитория через &lsquo;docker pull&rsquo;. Вы можете использовать &lsquo;docker rmi&rsquo; только для слоев верхнего уровня (или образов), для удаления промежуточных слоев нужно использовать &lsquo;docker rmi -f&rsquo;.</p>

<h3>docker commit <container-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/7d0/ec4/104/7d0ec41049b34238bb785e28897e28f0.png">https://habrastorage.org/files/7d0/ec4/104/7d0ec41049b34238bb785e28897e28f0.png</a>"> или <img class="<a" src="href="https://habrastorage.org/files/325/e8e/270/325e8e27098e4cdeb956634361879388.png">https://habrastorage.org/files/325/e8e/270/325e8e27098e4cdeb956634361879388.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/daa/69c/50f/daa69c50fbc3479ba9d6497983b73a02.png">https://habrastorage.org/files/daa/69c/50f/daa69c50fbc3479ba9d6497983b73a02.png</a>"></p>

<p>Команда &lsquo;docker commit&rsquo; берет верхний уровень контейнера, тот, что для записи и превращает его в слой для чтения. Это фактически превращает контейнер (вне зависимости от того, запущен ли он) в неизменяемый образ.</p>

<p><img class="<a" src="href="https://habrastorage.org/files/e3d/7d7/766/e3d7d7766165425a9148ac61369ffe9c.png">https://habrastorage.org/files/e3d/7d7/766/e3d7d7766165425a9148ac61369ffe9c.png</a>"></p>

<h3>docker build</h3>

<p>До:
Dockerfile <img class="<a" src="href="https://habrastorage.org/files/847/71b/87a/84771b87a8cd4d77b63d39a3ae9dae13.png">https://habrastorage.org/files/847/71b/87a/84771b87a8cd4d77b63d39a3ae9dae13.png</a>"> и <img class="<a" src="href="https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png">https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png">https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png</a>">
Со многими другими слоями.</p>

<p>Команда &lsquo;docker build&rsquo; интересна тем, что запускает целый ряд команд:
<img class="<a" src="href="https://habrastorage.org/files/b25/36e/cac/b2536ecac84148ba9a043bb00fe3ce5a.png">https://habrastorage.org/files/b25/36e/cac/b2536ecac84148ba9a043bb00fe3ce5a.png</a>"></p>

<p>На изображении выше мы видим, как команда build использует значение инструкции FROM из файла Dockerfile как базовый образ после чего:</p>

<p>1) запускает контейнер (create и start)
2) изменяет слой для записи
3) делает commit
На каждой итерации создается новый слой. При исполнении &lsquo;docker build&rsquo; может создаваться множество слоев.</p>

<h3>docker exec <running-container-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/7d0/ec4/104/7d0ec41049b34238bb785e28897e28f0.png">https://habrastorage.org/files/7d0/ec4/104/7d0ec41049b34238bb785e28897e28f0.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/4d6/cd5/21e/4d6cd521ee4d47e68d89e9ce77c8a6ca.png">https://habrastorage.org/files/4d6/cd5/21e/4d6cd521ee4d47e68d89e9ce77c8a6ca.png</a>"></p>

<p>Команда &lsquo;docker exec&rsquo; применяется к запущенному контейнеру, запускает новый процесс внутри пространства процессов контейнера.</p>

<h3>docker inspect <container-id> | <image-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/74c/7ee/e53/74c7eee53b8f4ed8a2a606e87571fe3a.png">https://habrastorage.org/files/74c/7ee/e53/74c7eee53b8f4ed8a2a606e87571fe3a.png</a>"> или <img class="<a" src="href="https://habrastorage.org/files/242/b58/b68/242b58b68acd4580b226569d81d613e5.png">https://habrastorage.org/files/242/b58/b68/242b58b68acd4580b226569d81d613e5.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/898/5e8/e54/8985e8e5467a42769988a4351d0c0828.png">https://habrastorage.org/files/898/5e8/e54/8985e8e5467a42769988a4351d0c0828.png</a>"></p>

<p>Команда &lsquo;docker inspect&rsquo; получает метаданные верхнего слоя контейнера или образа.</p>

<h3>docker save <image-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/f2a/b8d/70d/f2ab8d70de7a4ca4959f6a7bf1fb11e3.png">https://habrastorage.org/files/f2a/b8d/70d/f2ab8d70de7a4ca4959f6a7bf1fb11e3.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/d5d/bf7/3f0/d5dbf73f0f2d4d72b0ed38309e2c6a6b.png">https://habrastorage.org/files/d5d/bf7/3f0/d5dbf73f0f2d4d72b0ed38309e2c6a6b.png</a>"></p>

<p>Команда &lsquo;docker save&rsquo; создает один файл, который может быть использован для импорта образа на другую хост-систему. В отличие от команды &lsquo;export&rsquo;, она сохраняет все слои и их метаданные. Может быть применена только к образам.</p>

<h3>docker export <container-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/a7f/3f4/717/a7f3f47170084dc2b75dd73e8d6a5cbb.png">https://habrastorage.org/files/a7f/3f4/717/a7f3f47170084dc2b75dd73e8d6a5cbb.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/36d/807/ed6/36d807ed6b304333b31f658dfb5c4326.png">https://habrastorage.org/files/36d/807/ed6/36d807ed6b304333b31f658dfb5c4326.png</a>"></p>

<p>Команда &lsquo;docker export&rsquo; создает tar архив с содержимым файлов контейнера, в результате получается папка, пригодная для использования вне docker. Команда убирает слои и их метаданные. Может быть применена только для контейнеров.</p>

<h3>docker history <image-id></h3>

<p>До:
<img class="<a" src="href="https://habrastorage.org/files/428/150/afc/428150afc2574fd2bf32f1202c908f77.png">https://habrastorage.org/files/428/150/afc/428150afc2574fd2bf32f1202c908f77.png</a>"></p>

<p>После:
<img class="<a" src="href="https://habrastorage.org/files/e82/45f/511/e8245f51120340b19e07c6009f2d4ce8.png">https://habrastorage.org/files/e82/45f/511/e8245f51120340b19e07c6009f2d4ce8.png</a>"></p>

<p>Команда &lsquo;docker history&rsquo; принимает <image-id> и рекурсивно выводит список всех слоев-родителей образа (которые тоже могут быть образами)</p>

<h2>Итог</h2>

<p>Я надеюсь, вам понравилась эта визуализация контейнеров и образов. Есть много других команд (pull, search, restart, attach и другие), которые могут или не могут быть объяснены моими сравнениями.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Автоматическое скачивание торрентов с Weburg в Transmission и статистика на InfluxDB & Grafana]]></title>
    <link href="http://blog.popstas.ru/blog/2016/01/17/torrent-transmission-client-for-weburg/"/>
    <updated>2016-01-17T08:22:25+05:00</updated>
    <id>http://blog.popstas.ru/blog/2016/01/17/torrent-transmission-client-for-weburg</id>
    <content type="html"><![CDATA[<p>У моего интернет-провайдера Планета есть бонусная программа поощрения раздачи торрентов с <a href="http://weburg.net">weburg.net</a>, дающая бонусы,
их можно тратить на абонентскую плату. У меня комп постоянно включен, я сразу стал участвовать.</p>

<p>Поддержку раздач можно разбить на несколько задач:</p>

<ol>
<li>периодически скачивать новинки фильмов</li>
<li>скачивать новые серии популярных сериалов</li>
<li>удалять то, что плохо раздается</li>
</ol>


<p>Через пару месяцев мне это надоело, задумался об автоматизации этого процесса и вот в новогодние каникулы родился
<a href="https://github.com/popstas/transmission-cli">transmission-cli</a> - консольная утилита, решающая часть этих задач.</p>

<iframe src="https://ghbtns.com/github-btn.html?user=popstas&repo=transmission-cli&type=star&count=true&size=large" frameborder="0" scrolling="0" width="160px" height="30px"></iframe>


<p><a href="https://travis-ci.org/popstas/transmission-cli"><img src="https://travis-ci.org/popstas/transmission-cli.svg?branch=master" alt="Build Status" /></a>
<a href="https://coveralls.io/github/popstas/transmission-cli?branch=master"><img src="https://coveralls.io/repos/popstas/transmission-cli/badge.svg?branch=master&amp;service=github" alt="Coverage Status" /></a></p>

<p><img class="<a" src="href="https://github.com/popstas/transmission-cli/raw/master/docs/img/grafana.png?raw=true">https://github.com/popstas/transmission-cli/raw/master/docs/img/grafana.png?raw=true</a>"></p>

<!-- more -->


<h2>Возможности</h2>

<ul>
<li>скачивание популярных торрентов с <a href="http://weburg.net">http://weburg.net</a></li>
<li>удаление дублирующихся раздач (для сериалов)</li>
<li>отправка метрик в InfluxDB (для слежения за популярностью)</li>
</ul>


<h1>Установка</h1>

<p>Установить клиент можно так:
<code>bash
latest_phar=$(curl -s https://api.github.com/repos/popstas/transmission-cli/releases/latest | grep 'browser_' | cut -d\" -f4)
wget -O /usr/local/bin/transmission-cli "$latest_phar"
chmod +x /usr/local/bin/transmission-cli
</code></p>

<p>Пользоваться графиками можно с трудом, потому что InfluxDB и Grafana вам придется устанавливать самостоятельно.
Я ставил то и другое в docker на свою виртуалку и пробрасывал порты на localhost,
сейчас localhost вшит в <a href="https://github.com/popstas/transmission-cli/blob/master/src/Config.php">конфиг</a>,
который по сути сейчас находится в коде.</p>

<p>Поставить можно так, заменив папки <code>/Users/popstas/lib/grafana</code> и <code>/var/lib/influxdb</code> на ваши,
это укажет, где будут храниться данные InfluxDB и Grafana:
<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>docker run -d <span class="se">\ </span>-p 3000:3000 <span class="se">\</span>
</span><span class='line'>           -v /Users/popstas/lib/grafana:/var/lib/grafana <span class="se">\</span>
</span><span class='line'>            <span class="p">&amp;</span>ndash<span class="p">;</span>name grafana grafana/grafana&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;docker run -d -p 8083:8083 -p 8086:8086 <span class="se">\</span>
</span><span class='line'>           -v /var/lib/influxdb:/data <span class="se">\</span>
</span><span class='line'>           <span class="p">&amp;</span>ndash<span class="p">;</span>name influxdb tutum/influxdb
</span></code></pre></td></tr></table></div></figure></p>

<p>Папку от InfluxDB я оставил в виртуалке, т.к. оказалось, что InfluxDB не может работать с папкой, смонтированной в
VirtualBox из Mac OS (какой-то старый глюк docker).</p>

<p>Чтобы собиралась статистика, нужно добавить в cron задания, я собираю с 2 компов, поэтому добавляю 2 раза.</p>

<p>Также, чтобы не было конфликтов, статистика не будет отсылаться, если найдет раздачи с одинаковыми названиями,
которые обычно остаются от сериалов. Поэтому их нужно чистить перед отпправкой статистики.</p>

<p>Раздачи у меня скачиваются в папку, за которой следят оба Transmission, как только туда попадает торрент, раздача
сразу начинается (можно сделать, чтобы спрашивала разрешение, настраивается в Transmission).</p>

<p>В итоге у меня получился такой cron:
<code>
PATH="$PATH:/usr/local/bin"
59 * * * * transmission-cli remove-duplicates --host=localhost
59 * * * * transmission-cli remove-duplicates --host=wrtnsq
0  * * * * transmission-cli send-metrics --host=localhost
0  * * * * transmission-cli send-metrics --host=wrtnsq
1  2 * * * transmission-cli download-weburg --dest=/Volumes/media/_planeta/_torrents
</code></p>

<h2>Результаты статистики</h2>

<p>Никогда не знал о своих раздачах ничего, кроме рейтинга и объема розданного за все время.
Графики показали интересные вещи (о которых можно было и так догадаться):</p>

<ul>
<li>с 18 до 22 пик раздач, с 22 до 2 спад, с 2 до 9 все спят</li>
<li>в праздники и выходные больше качают днем и до ночи, но после 2 все равно все спят</li>
<li>популярные фильмы популярны обычно не больше недели</li>
<li>есть популярные фильмы, которые популярны и через несколько месяцев, например &ldquo;Интерстеллар&rdquo;</li>
</ul>


<p>Сейчас я могу выбрать в Grafana период в 7 дней, отсортировать раздачи по розданным Гб и получить список
раздач-кандидатов на удаление.</p>

<p>Со статистикой еще надо работать, что еще хочется сделать:</p>

<ul>
<li><p>нормальную группировку по периодам, сейчас группируется только за час или за весь выбранный период,
нельзя выбрать последнюю неделю и посмотреть посуточные метрики. Я скидываю метрики и сначала не понимал,
почему так, но тут как раз вышла статья
<a href="http://habrahabr.ru/post/274303/">Почему расчет перцентилей работает не так как вы ожидаете?</a> и многое мне объяснила.</p></li>
<li><p>добавить в метрики инфу о весе раздач и вывести эффективность раздач: например, фильм в 1080p весом в 10 Гб
скачали на 50 Гб за неделю, а 2 Гб фильм низкого качества скачали на 10 Гб, если не учитывать вес раздач, то выходит,
что первая раздача в 5 раз эффективнее, но если учитвать, то оказвается, что они равны.</p></li>
</ul>


<h2>Техническая часть:</h2>

<ul>
<li>Symfony console - каркас консольной утилиты</li>
<li>InfluxDB - хранилище метрик</li>
<li>Grafana - рисование графиков</li>
<li>Composer - управление зависимостями</li>
<li>Box - <a href="http://habrahabr.ru/post/274745/">сборка PHAR</a></li>
<li>PHPCS, PHPMD - линтеры PHP</li>
<li>Travis CI - публицация PHAR на Github</li>
<li>Coveralls - сервис слежения за покрытием кода тестами</li>
</ul>


<p>Половину из этого я ни разу не использовал, вторую половину - немного. Поэтому граблей хватает.</p>

<h3>Symfony console</h3>

<p>Тут мне сказать особо нечего, фреймворки я только начинаю осваивать, пока ничего не понятно с Dependency Injection,
чувствую, что у меня переменные в функции местами прокидываются криво, а местами не прокидываются, где стоило бы.</p>

<p>Не понятно, как тестить через PHPUnit, как мокать объекты.</p>

<p>Пока радуюсь, что освоился с namespaces и использовал на практике PSR-2 и PSR-4.</p>

<p>Почти все идеи взяты из исходников
<a href="https://github.com/composer/composer">composer</a> и
<a href="https://github.com/MartialGeek/transmission-api">transmission-api</a></p>

<h3>InfluxDB</h3>

<p>InfluxDB не может работать с папкой, смонтированной в VirtualBox из Mac OS (какой-то старый глюк docker).</p>

<p>InfluxDB я раньше не видел, хотел посмотреть ее как замену для хранилища Whisper из стека
Diamond -> Carbon -> Whisper -> Graphite -> Grafana для рисования графиков сервера.</p>

<p>Компания, стоящая за InfluxDB с недавнего времени назвается InfluxData и предлагает свой стек
<a href="https://influxdata.com/time-series-platform/">TICK</a>, в который
входит еще и алертинг по отклонениям метрик. Могу сказать о нем то, что Telegraf работает, InfluxDB работает без тормозов,
собирая с моего компа метрики раз в 10 секунд, Chronograf какой-то неполноценный, по сравнению с Grafana,
а Kapacitor я еще не смотрел (UPD 19.05.2016: <a href="/blog/categories/kapacitor/">уже смотрел</a>).</p>

<h3>Grafana</h3>

<p>В Grafana 2.6 появилось много нового, по сравнению с 2.0, которую я видел в августе. А вообще, если кто использовал
Cacti или Graphite и не видел Grafana, посмотрите, красота неописуемая.</p>

<h3>Composer</h3>

<p>Некоторые dev-пакеты (phpunit) потребовали php 5.6 для запуска, поэтому поставил 5.6 минимальной необходимой версией,
хотя по факту клиент может работать и на 5.5, а на 5.4 уже не может.</p>

<h3>Box</h3>

<p>Если собирать PHAR, используя box, установленный через composer, в архив попадает много ненужных dev-пакетов.
Сначала я пытался бороться с этим исключением пакетов через box.json, потом понял, что это бесполезно
(все пакеты не исключишь, а однажды исключишь нужный), в итоге пришел к такой схеме:</p>

<ul>
<li>ставим пакеты через <code>composer install --no-dev</code></li>
<li>качаем box.phar</li>
<li>собираем transmission-cli.phar</li>
<li>доставляем пакеты через composer update</li>
</ul>


<p>Это в 3 раза уменьшило вес собранного архива.</p>

<h3>PHPCS, PHPMD</h3>

<p>PHP Code Sniffer умеет анализировать ваш код на соответствие определенным стандартам, в моем случае PSR-2,
ставится через Composer, используется так:
<code>
./vendor/bin/phpcs --standard=psr2 ./src
</code></p>

<p>А PHP Mess Detector у меня не запустился.</p>

<h3>Travis CI</h3>

<p>Впервые удалось использовать его по назначению. Как-то пробовал использовать его для тестов пакета bash скриптов
<a href="https://github.com/popstas/drupal-scripts">drupal-scripts</a>, но быстро сдался, т.к. в окружении travis они вели себя не так,
как на локалке (в итоге перекинул тесты на TeamCity).</p>

<p>На этом проекте travis прогоняет тесты phpunit
(тестов по сути еще нет, но без phpunit в каком-либо виде travis по умолчанию фейлит сборку)
и если к коммиту был проставлен git tag,
публикует PHAR как приложение к релизу на Github, чуть подробнее я написал
в <a href="http://habrahabr.ru/post/274745/#comment_8736379">этом комменте</a>.</p>

<h3>Coveralls</h3>

<p>До покрытия тестами я еще не добирался, я тесты-то еще только начинаю использовать, решил попробовать на этом проекте.</p>

<p>Чтобы добавить coveralls в самом простом случае (в доках есть и сложные), достаточно сделать так, чтобы PHPUnit
генерил файл <code>build/logs/clover.xml</code>, для этого надо добавить строчку в phpunit.xml, в секцию logging:
<code>xml
&lt;logging&gt;
    &lt;log type="coverage-clover" target="build/logs/clover.xml"/&gt;
&lt;/logging&gt;
</code>
Ну и конечно зарегаться на <a href="https://coveralls.io/">https://coveralls.io/</a> и активировать там проект.
Если путь будет другой, придется читать доки и создавать файл настройки .coveralls.yml</p>

<p>В результате я имею красивую красную ачивку на странице проекта
и <a href="https://coveralls.io/github/popstas/transmission-cli">историю деградации покрытия</a> :)</p>
]]></content>
  </entry>
  
</feed>
